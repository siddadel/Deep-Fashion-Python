{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import merge, Input\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "#import tf.kerasTasm\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# Loading the training data\n",
    "from PIL import ImageOps\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-1\n",
      "\n",
      "Loaded the images of dataset-0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define data path\n",
    "data_path = r'/floyd/input/images/Number'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "data_dir_list\n",
    "\n",
    "df = pd.read_csv('/floyd/input/csv/images.csv', header=None)\n",
    "arr = df[2].unique() \n",
    "df[2] = df[2].transform(lambda x: np.array(np.where(arr == x)).item())\n",
    "\n",
    "desired_size = 224\n",
    "\n",
    "img_data_list=[]\n",
    "price_list = []\n",
    "sales = np.array([])\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(os.path.join(data_path,dataset))\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))  \n",
    "    for img in img_list:\n",
    "        stem = Path(img).stem     \n",
    "        img_path = os.path.join(data_path, dataset, img)\n",
    "        img = image.load_img(img_path, target_size=(desired_size, desired_size))\n",
    "        # img = img.resize((desired_size, desired_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)   \n",
    "        \n",
    "        price = np.array([\n",
    "                df.loc[df[0] == stem, 5].iloc[0], #price\n",
    "                df.loc[df[0] == stem, 2].iloc[0], #color family\n",
    "                df.loc[df[0] == stem, 3].iloc[0], #class\n",
    "                df.loc[df[0] == stem, 4].iloc[0], #style\n",
    "                int(stem.split('_')[1]) #color\n",
    "            ])\n",
    "        \n",
    "        price_list.append(price)\n",
    "        img_data_list.append(x)\n",
    "        img.close()       \n",
    "    sales = np.append(sales, np.full((len(img_list),), int(dataset),dtype='float64') )\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "price_data = np.array(price_list)\n",
    "\n",
    "\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "img_data=img_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data, price_data, sales = shuffle(img_data, price_data, sales, random_state=2)\n",
    "img_data_train, img_data_test, price_data_train, price_data_test, sales_train, sales_test = train_test_split(img_data, price_data, sales, test_size=0.1, random_state=2) # TAKES TIME\n",
    "img_data_val, img_data_test, price_data_val, price_data_test, sales_val, sales_test = train_test_split(img_data_test, price_data_test, sales_test, test_size=0.5, random_state=2) # TAKES TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/floyd/input/images/Number/1\n",
      "Loaded the images of dataset-1 for augmentation\n"
     ]
    }
   ],
   "source": [
    "dataset = '1'\n",
    "img_data_list=[]\n",
    "price_list = []\n",
    "img_list=os.listdir(os.path.join(data_path, dataset))\n",
    "print(os.path.join(data_path,'1'))\n",
    "print ('Loaded the images of dataset-1 for augmentation')  \n",
    "for img in img_list:\n",
    "    stem = Path(img).stem     \n",
    "    img_path = os.path.join(data_path, dataset, img)\n",
    "    img = image.load_img(img_path, target_size=(desired_size, desired_size))\n",
    "    x = image.img_to_array(ImageOps.mirror(img))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)   \n",
    "        \n",
    "    price = np.array([\n",
    "                df.loc[df[0] == stem, 5].iloc[0], #price\n",
    "                df.loc[df[0] == stem, 2].iloc[0], #color family\n",
    "                df.loc[df[0] == stem, 3].iloc[0], #class\n",
    "                df.loc[df[0] == stem, 4].iloc[0], #style\n",
    "                int(stem.split('_')[1]) #color\n",
    "            ])\n",
    "        \n",
    "    price_list.append(price)\n",
    "    img_data_list.append(x)\n",
    "    img.close()\n",
    "sales = np.full((len(img_list),), 1, dtype='float64')\n",
    "img_data = np.array(img_data_list)\n",
    "price_data = np.array(price_list)\n",
    "\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "img_data=img_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9369, 224, 224, 3)\n",
      "(3749, 224, 224, 3)\n",
      "(9369, 5)\n",
      "(3749, 5)\n",
      "(9369,)\n",
      "(3749,)\n"
     ]
    }
   ],
   "source": [
    "sales_train.reshape((sales_train.shape[0], 1))\n",
    "sales.reshape((sales.shape[0], 1))\n",
    "print(img_data_train.shape)\n",
    "print(img_data.shape)\n",
    "print(price_data_train.shape)\n",
    "print(price_data.shape)\n",
    "print(sales_train.shape)\n",
    "print(sales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13118, 224, 224, 3)\n",
      "(13118, 5)\n"
     ]
    }
   ],
   "source": [
    "img_data_train = np.vstack((img_data_train, img_data))\n",
    "price_data_train = np.vstack((price_data_train, price_data))\n",
    "print(img_data_train.shape)\n",
    "print(price_data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13118,)\n"
     ]
    }
   ],
   "source": [
    "sales_train = np.append(sales_train, sales,axis = 0)\n",
    "print(sales_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_train, price_data_train, sales_train = shuffle(img_data_train, price_data_train, sales_train, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "image_input = Input(shape=(desired_size, desired_size, 3))\n",
    "\n",
    "conv = InceptionV3(input_tensor=image_input, include_top=True, weights='imagenet')\n",
    "image_encoding = conv.get_layer('predictions').output\n",
    "\n",
    "\n",
    "\n",
    "price_input = Input(shape=(price_data_train.shape[1],))\n",
    "price_encoding = Dense(10, activation='relu')(price_input)\n",
    "price_encoding = Dense(10, activation='relu')(price_encoding)\n",
    "\n",
    "concatenated = layers.concatenate([image_encoding, price_encoding], axis=-1)\n",
    "\n",
    "sales_output = Dense(1, activation='sigmoid', name='output')(concatenated)\n",
    "98\n",
    "model = Model([image_input, price_input], sales_output)\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13118 samples, validate on 520 samples\n",
      "Epoch 1/40\n",
      "13118/13118 [==============================] - 83s 6ms/step - loss: 2.9700 - binary_accuracy: 0.5068 - val_loss: 2.2736 - val_binary_accuracy: 0.6462\n",
      "Epoch 2/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 2.4699 - binary_accuracy: 0.4985 - val_loss: 0.6856 - val_binary_accuracy: 0.5865\n",
      "Epoch 3/40\n",
      "13118/13118 [==============================] - 76s 6ms/step - loss: 2.2512 - binary_accuracy: 0.4976 - val_loss: 4.3922 - val_binary_accuracy: 0.3500\n",
      "Epoch 4/40\n",
      "13118/13118 [==============================] - 76s 6ms/step - loss: 2.0904 - binary_accuracy: 0.4965 - val_loss: 0.8387 - val_binary_accuracy: 0.3673\n",
      "Epoch 5/40\n",
      "13118/13118 [==============================] - 76s 6ms/step - loss: 1.9793 - binary_accuracy: 0.5052 - val_loss: 2.6247 - val_binary_accuracy: 0.3481\n",
      "Epoch 6/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 1.8465 - binary_accuracy: 0.5047 - val_loss: 1.1175 - val_binary_accuracy: 0.3615\n",
      "Epoch 7/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 1.6977 - binary_accuracy: 0.5053 - val_loss: 1.3216 - val_binary_accuracy: 0.3692\n",
      "Epoch 8/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 1.5837 - binary_accuracy: 0.5047 - val_loss: 1.7819 - val_binary_accuracy: 0.6481\n",
      "Epoch 9/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 1.4766 - binary_accuracy: 0.5035 - val_loss: 2.4691 - val_binary_accuracy: 0.3577\n",
      "Epoch 10/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 1.3334 - binary_accuracy: 0.5116 - val_loss: 1.2713 - val_binary_accuracy: 0.3558\n",
      "Epoch 11/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 1.1945 - binary_accuracy: 0.5067 - val_loss: 0.7071 - val_binary_accuracy: 0.5077\n",
      "Epoch 12/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 1.0515 - binary_accuracy: 0.5087 - val_loss: 0.7288 - val_binary_accuracy: 0.4462\n",
      "Epoch 13/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.9026 - binary_accuracy: 0.5132 - val_loss: 0.7054 - val_binary_accuracy: 0.4846\n",
      "Epoch 14/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.7994 - binary_accuracy: 0.5195 - val_loss: 0.6669 - val_binary_accuracy: 0.6077\n",
      "Epoch 15/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.7179 - binary_accuracy: 0.5249 - val_loss: 0.7193 - val_binary_accuracy: 0.3500\n",
      "Epoch 16/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6912 - binary_accuracy: 0.5441 - val_loss: 0.7137 - val_binary_accuracy: 0.4173\n",
      "Epoch 17/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5433 - val_loss: 0.7232 - val_binary_accuracy: 0.3635\n",
      "Epoch 18/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6899 - binary_accuracy: 0.5455 - val_loss: 0.7244 - val_binary_accuracy: 0.3538\n",
      "Epoch 19/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5430 - val_loss: 0.7190 - val_binary_accuracy: 0.3558\n",
      "Epoch 20/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6902 - binary_accuracy: 0.5447 - val_loss: 0.7207 - val_binary_accuracy: 0.3500\n",
      "Epoch 21/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6928 - binary_accuracy: 0.5420 - val_loss: 0.7196 - val_binary_accuracy: 0.3500\n",
      "Epoch 22/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6915 - binary_accuracy: 0.5425 - val_loss: 0.7229 - val_binary_accuracy: 0.3558\n",
      "Epoch 23/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6899 - binary_accuracy: 0.5446 - val_loss: 0.7163 - val_binary_accuracy: 0.3596\n",
      "Epoch 24/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6895 - binary_accuracy: 0.5447 - val_loss: 0.7184 - val_binary_accuracy: 0.3538\n",
      "Epoch 25/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6890 - binary_accuracy: 0.5452 - val_loss: 0.7256 - val_binary_accuracy: 0.3538\n",
      "Epoch 26/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6890 - binary_accuracy: 0.5452 - val_loss: 0.7343 - val_binary_accuracy: 0.3577\n",
      "Epoch 27/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6892 - binary_accuracy: 0.5454 - val_loss: 0.7090 - val_binary_accuracy: 0.3615\n",
      "Epoch 28/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6872 - binary_accuracy: 0.5456 - val_loss: 0.7056 - val_binary_accuracy: 0.3654\n",
      "Epoch 29/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6889 - binary_accuracy: 0.5467 - val_loss: 0.7106 - val_binary_accuracy: 0.3596\n",
      "Epoch 30/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6920 - binary_accuracy: 0.5458 - val_loss: 0.7154 - val_binary_accuracy: 0.3615\n",
      "Epoch 31/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6900 - binary_accuracy: 0.5467 - val_loss: 0.7204 - val_binary_accuracy: 0.3635\n",
      "Epoch 32/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6888 - binary_accuracy: 0.5459 - val_loss: 0.7151 - val_binary_accuracy: 0.3615\n",
      "Epoch 33/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6968 - binary_accuracy: 0.5463 - val_loss: 0.7183 - val_binary_accuracy: 0.3635\n",
      "Epoch 34/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6950 - binary_accuracy: 0.5459 - val_loss: 0.7158 - val_binary_accuracy: 0.3635\n",
      "Epoch 35/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6954 - binary_accuracy: 0.5462 - val_loss: 0.7147 - val_binary_accuracy: 0.3635\n",
      "Epoch 36/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6893 - binary_accuracy: 0.5464 - val_loss: 0.7161 - val_binary_accuracy: 0.3615\n",
      "Epoch 37/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6917 - binary_accuracy: 0.5470 - val_loss: 0.7163 - val_binary_accuracy: 0.3635\n",
      "Epoch 38/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6886 - binary_accuracy: 0.5463 - val_loss: 0.7179 - val_binary_accuracy: 0.3615\n",
      "Epoch 39/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6890 - binary_accuracy: 0.5471 - val_loss: 0.7178 - val_binary_accuracy: 0.3635\n",
      "Epoch 40/40\n",
      "13118/13118 [==============================] - 75s 6ms/step - loss: 0.6885 - binary_accuracy: 0.5480 - val_loss: 0.7143 - val_binary_accuracy: 0.3635\n",
      "Training time: 3028.2521624565125\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "numpy() is only available when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-68088dc1703d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_write_to_gcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[0;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# write as binary stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, h5dict, include_optimizer)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 'optimizer_config': {\n\u001b[1;32m    178\u001b[0m                     \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                 },\n\u001b[1;32m    181\u001b[0m                 \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         config = {'learning_rate': float(K.get_value(self.learning_rate)),\n\u001b[0m\u001b[1;32m    296\u001b[0m                   \u001b[0;34m'rho'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                   \u001b[0;34m'decay'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    582\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     raise NotImplementedError(\n\u001b[0;32m--> 584\u001b[0;31m         \"numpy() is only available when eager execution is enabled.\")\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Prefer Dataset.range instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: numpy() is only available when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "hist = model.fit([img_data_train, price_data_train], sales_train, batch_size=32, epochs=40, verbose=1, validation_data=([img_data_val, price_data_val], sales_val))\n",
    "\n",
    "print('Training time: %s' % (time.time() - t))\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.02      0.04       324\n",
      "         1.0       0.38      0.99      0.55       197\n",
      "\n",
      "    accuracy                           0.39       521\n",
      "   macro avg       0.63      0.51      0.30       521\n",
      "weighted avg       0.69      0.39      0.23       521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import itertools\n",
    "#################################################################\n",
    "sales_pred = model.predict([img_data_test, price_data_test]) # NO OF IMAGES x NUMBER OF CLASSES\n",
    "sales_pred = np.round(sales_pred) # required to bring to proper format 1xcol\n",
    "\n",
    "\n",
    "#%%\n",
    "print(classification_report(sales_test, sales_pred)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This model with 5 csv params gave around 68% on set of 30 and on 102-135 set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
